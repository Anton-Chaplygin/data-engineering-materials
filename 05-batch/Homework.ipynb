{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8199d74-649e-4ff4-b0bf-dcbda7316363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a32814-d66a-42ca-94ed-b91a5b63bdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b949607-39fa-4d58-9f98-f960f832edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ae6bb4-32be-4981-b916-932010c7f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/10 18:17:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/10 18:17:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/10 18:17:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"My app\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecaa7bd-98bc-4d6c-a9fb-1e0b1395c428",
   "metadata": {},
   "source": [
    "## Task - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40287a42-df53-4d24-a32f-76d39c3c540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-10 17:58:50--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 4.208.26.197\n",
      "Connecting to github.com (github.com)|4.208.26.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240310T175850Z&X-Amz-Expires=300&X-Amz-Signature=41fe3b231c6646169b660755d3bc8c22ed91b65ca863e0c69586dc4e202b770b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-10 17:58:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240310T175850Z&X-Amz-Expires=300&X-Amz-Signature=41fe3b231c6646169b660755d3bc8c22ed91b65ca863e0c69586dc4e202b770b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  44.5MB/s    in 0.4s    \n",
      "\n",
      "2024-03-10 17:58:51 (44.5 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752157a1-1e62-43d9-9371-e79f0dede4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d01b0528-d550-4988-aea1-ff6d1ddc7da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be88ccf0-3711-4fc4-82a4-1e3a614c7978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9bc4df-38a3-43d2-bf3c-9d4eae8e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9178b2-bfc7-43c2-a792-ee8a9eac20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "\ttypes.StructField('dispatching_base_num', types.StringType(), True), \n",
    "\ttypes.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "\ttypes.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "\ttypes.StructField('PUlocationID', types.IntegerType(), True), \n",
    "\ttypes.StructField('DOlocationID', types.IntegerType(), True), \n",
    "\ttypes.StructField('SR_Flag', types.StringType(), True), \n",
    "\ttypes.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f414c48b-b560-4379-b267-4f3b7a558f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb19f18a-d871-46ce-8f54-9fb640d5dfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropOff_datetime', TimestampType(), True), StructField('PUlocationID', IntegerType(), True), StructField('DOlocationID', IntegerType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "386eecc2-5b42-4f23-b5be-f7741eeefa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e05e9a-6d4e-4036-8acb-eb58515e4bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv_tripdata/2019/10/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea3014-d1be-4f75-a999-ee29bb490f46",
   "metadata": {},
   "source": [
    "## Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd0d50b4-61ac-480f-8304-b300e61d2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4df94be4-28f0-4d80-900d-90c47306808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv_tripdata/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba810d65-2794-4da2-8f53-142f1803ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58a2f648-e207-4705-95bb-8069e6a76895",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'dispatching_base_num' , \n",
    "    'pickup_datetime' , \n",
    "    'dropOff_datetime', \n",
    "    'PUlocationID', \n",
    "    'DOlocationID', \n",
    "    'SR_Flag', \n",
    "    'Affiliated_base_number',\n",
    "    'pickup_date',\n",
    "    'dropOff_date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "260acd1d-1bb4-49e4-9f5e-efdb01754d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropOff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "    .select(columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55cfc1e1-eccb-44f9-9012-2d440196fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|62610|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .filter(df.pickup_date == '2019-10-15') \\\n",
    "    .groupBy() \\\n",
    "    .count() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87188969-caba-42ef-9f85-a8614831f591",
   "metadata": {},
   "source": [
    "## Task - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3af132e0-ac52-41c8-8cfb-e752997508bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton_chaplygin/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06db0248-6ccd-4c6a-95c1-0b5d35e1cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_duration|\n",
      "+-------------+\n",
      "|       631152|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "        MAX(datediff(dropOff_datetime, pickup_datetime) * 24) as trip_duration\n",
    "FROM trips_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59f7b1-9022-42fb-b881-b550f285f06b",
   "metadata": {},
   "source": [
    "## Task - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2554d-d13f-4f8b-96ba-8960bd27e379",
   "metadata": {},
   "source": [
    "what is the name of the LEAST frequent pickup location Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96017dff-91f6-46f7-8f7f-e82ef184caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-10 19:29:00--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240310T192900Z&X-Amz-Expires=300&X-Amz-Signature=11c0c28942dbd89d5cb3ce88bcf227f169b14c9b740ddaf8aa2b70b036e6025d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-10 19:29:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240310T192900Z&X-Amz-Expires=300&X-Amz-Signature=11c0c28942dbd89d5cb3ce88bcf227f169b14c9b740ddaf8aa2b70b036e6025d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-10 19:29:01 (35.4 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58b5c66b-6306-4f20-95ca-716e15fd474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f2d4f3b-9fbb-4058-805d-25628c0011ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ba3b45e-d749-40eb-b916-31833b669445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton_chaplygin/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "zone.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29b09ba9-6a74-48d2-b820-3b10430a51f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|       Zone|count(1)|\n",
      "+-----------+--------+\n",
      "|Jamaica Bay|       1|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "        z.Zone,\n",
    "        count(*)\n",
    "FROM trips_data td\n",
    "LEFT JOIN zones z ON TRUE\n",
    "    AND td.PUlocationID = z.LocationID\n",
    "GROUP BY 1\n",
    "ORDER BY 2\n",
    "LIMIT 1\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
